{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember:\n",
    "* Regression Model: Predicts a value.  \n",
    "* Classification: Gives a state.  \n",
    "\n",
    "#### Testing in Sklearn:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    Y,\n",
    "                                                   test_size = 0.25)\n",
    "```\n",
    "\n",
    "##### Testing Rule:\n",
    "> Never use the testing data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a table that will describe the perfomance of a model.  \n",
    "It stores the values of:\n",
    "* True Negative  \n",
    "* False Negative  \n",
    "* True Positive  \n",
    "* False Positive\n",
    "\n",
    "![Confusion Matrix](./confusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $Accuracy = (True Positives + True Negatives)/ Total$\n",
    " \n",
    " #### Accuracy in Sklearn:  \n",
    " ```python\n",
    " from sklearn.metrics import accuracy_score\n",
    " accuracy_score (y_true, y_pred)\n",
    " ```\n",
    " ##### Accuracy Example:  \n",
    " ![Accuracy](./accuracy.png)\n",
    " Accuracy = 78.57%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Mean Absolute Error***\n",
    "    It's not differentiable, so can't use gradient descent.  \n",
    "    *Completar com Uso no ScikitLearn*\n",
    "* ***Mean Squared Error***\n",
    "    It's differentiable, so it can be used with the gradient descent.  \n",
    "    *Completar com uso no scikitlearn*\n",
    "* ***R2 Score*** = 1 - (Linear Regression Model Error/Simple Model Error)\n",
    "    * Bad Model: Errors are similar, so R2 is close to 0.  \n",
    "    * Good Model: The mean squared error for the linear regression is smaller     than the error for the simple model, so R2 is close to 1  \n",
    "    *Completar com uso no scikitlearn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When you oversimplify the problem : **Underfitting**\n",
    "* When you overcomplicating the problem: **Overfitting**\n",
    "#### Underfitting:\n",
    "* Does not do well in the training set.\n",
    "* Error due to bias.\n",
    "#### Overfitting:\n",
    "* Does well in the training set, but it tends to memorize it instead of learning the characteristics of it.\n",
    "* Error due to variance.\n",
    "#### Good Model\n",
    "> Must find a balance between the high bias(**Underfitting**) and the high variance(**Overfitting**), so the balance is the **Good Model** and do well in the training and testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Complexity Graph\n",
    "**Example of Errors:**\n",
    "![Training and Testing Errors](./complexity.png) \n",
    "**Training Error: 0**  \n",
    "**Testing Error: 2**  \n",
    "  \n",
    "**Model Complexity Graph Example:**\n",
    "![Model Complexity Graph](./bias-vs-variance-tradeoff.png)\n",
    "##### Broke the Test Rule:\n",
    "> Never use the testing data for training.  \n",
    "\n",
    "To fix this we must use the **Cross Validation**.  \n",
    "#### Cross Validation\n",
    "It's a set that will be used to make de decisions, instead of using the Testing Set with the Training Set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "It's a method to use all the dataset, and not lose data when splitting between testing and training, you create **K** buckets of data, then you train your model **K** times, each time using a different bucket as the testing set and the remaining buckets as the training set, then you average the results to get the final model.\n",
    "#### Cross validation in Sklearn\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(12,3)\n",
    "\n",
    "for train_indice, test_indices in kf:\n",
    "    print train_indices, test_indices\n",
    "```\n",
    "#### Randomizing the Data\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(12,3,shuffle=True)\n",
    "\n",
    "for train_indice, test_indices in kf:\n",
    "    print train_indices, test_indices\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
